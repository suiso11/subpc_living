"""
éŸ³å£°å¯¾è©±ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
Phase 3: VAD â†’ STT â†’ LLM (Ollama) â†’ TTS â†’ å†ç”Ÿ
Phase 2 ã®ãƒãƒ£ãƒƒãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨çµ±åˆ
"""
import sys
import time
import threading
import queue
import numpy as np
from pathlib import Path
from typing import Optional

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.audio.stt import WhisperSTT
from src.audio.tts import KokoroTTS
from src.audio.vad import EnergyVAD
from src.audio.audio_io import AudioRecorder, AudioPlayer
from src.chat.client import OllamaClient
from src.chat.session import ChatSession
from src.chat.config import ChatConfig


class VoicePipeline:
    """éŸ³å£°å¯¾è©±ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    # çŠ¶æ…‹å®šç¾©
    STATE_IDLE = "idle"
    STATE_LISTENING = "listening"
    STATE_PROCESSING = "processing"
    STATE_SPEAKING = "speaking"

    def __init__(
        self,
        chat_config: Optional[ChatConfig] = None,
        stt_model: str = "small",
        tts_models_dir: str = "models/tts/kokoro",
        tts_voice: str = "jf_alpha",
    ):
        # ãƒãƒ£ãƒƒãƒˆè¨­å®š
        self.config = chat_config or ChatConfig.load(PROJECT_ROOT / "config" / "chat_config.json")

        # STT (faster-whisper)
        self.stt = WhisperSTT(
            model_size=stt_model,
            language="ja",
            device="cpu",
            compute_type="int8",
        )

        # TTS (kokoro-onnx)
        self.tts = KokoroTTS(
            models_dir=PROJECT_ROOT / tts_models_dir,
            voice=tts_voice,
        )

        # VAD
        self.vad = EnergyVAD(
            sample_rate=16000,
            energy_threshold=0.01,
            silence_duration_ms=800,
            min_speech_duration_ms=300,
        )

        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª I/O
        self.recorder = AudioRecorder(sample_rate=16000)
        self.player = AudioPlayer(sample_rate=24000)

        # LLM
        self.llm = OllamaClient(
            base_url=self.config.ollama_base_url,
            model=self.config.model,
        )

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³
        self.session = ChatSession(
            system_prompt=self.config.system_prompt,
            max_history_turns=self.config.max_history_turns,
            history_dir=str(PROJECT_ROOT / self.config.history_dir),
        )

        # çŠ¶æ…‹
        self._state = self.STATE_IDLE
        self._running = False
        self._audio_queue: queue.Queue = queue.Queue()

    @property
    def state(self) -> str:
        return self._state

    def initialize(self) -> bool:
        """
        å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–ã€‚èµ·å‹•æ™‚ã«1å›å‘¼ã¶ã€‚

        Returns:
            æˆåŠŸã—ãŸã‚‰ True
        """
        print("=" * 50)
        print(" éŸ³å£°å¯¾è©±ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ åˆæœŸåŒ–")
        print("=" * 50)

        # Ollama æ¥ç¶šãƒã‚§ãƒƒã‚¯
        print("\n[1/4] Ollama æ¥ç¶šç¢ºèª...")
        if not self.llm.is_available():
            print("âŒ Ollamaã«æ¥ç¶šã§ãã¾ã›ã‚“")
            return False
        print("âœ… Ollama OK")

        # STT ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        print("\n[2/4] STT ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰...")
        try:
            self.stt.load()
            print("âœ… STT OK")
        except Exception as e:
            print(f"âŒ STT ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return False

        # TTS ãƒã‚§ãƒƒã‚¯
        print("\n[3/4] TTS ç¢ºèª...")
        try:
            self.tts.load()
            print("âœ… TTS OK")
        except Exception as e:
            print(f"âŒ TTS ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return False

        # VAD ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        print("\n[4/4] VAD ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")
        try:
            print("  ç’°å¢ƒãƒã‚¤ã‚ºã‚’è¨ˆæ¸¬ä¸­ (2ç§’é–“ã€é™ã‹ã«ã—ã¦ãã ã•ã„)...")
            noise_sample = self.recorder.record(2.0)
            self.vad.calibrate(noise_sample)
            print("âœ… VAD OK")
        except Exception as e:
            print(f"âš ï¸  VAD ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ã‚’ä½¿ç”¨): {e}")

        print("\n" + "=" * 50)
        print(" âœ… åˆæœŸåŒ–å®Œäº†ï¼")
        print("=" * 50)
        return True

    def process_voice_turn(self) -> Optional[str]:
        """
        1ã‚¿ãƒ¼ãƒ³ã®éŸ³å£°å¯¾è©±ã‚’å‡¦ç†ã™ã‚‹:
        éŒ²éŸ³ â†’ STT â†’ LLM â†’ TTS â†’ å†ç”Ÿ

        Returns:
            AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã€‚ã‚¨ãƒ©ãƒ¼æ™‚ã¯ Noneã€‚
        """
        # --- ãƒªã‚¹ãƒ‹ãƒ³ã‚° ---
        self._state = self.STATE_LISTENING
        print("\nğŸ¤ èã„ã¦ã„ã¾ã™... (è©±ã—çµ‚ã‚ã£ãŸã‚‰è‡ªå‹•æ¤œå‡ºã—ã¾ã™)")

        speech_audio = self._listen_for_speech()
        if speech_audio is None or len(speech_audio) < self.vad.sample_rate * 0.3:
            return None

        # --- STT ---
        self._state = self.STATE_PROCESSING
        print("\nğŸ”„ éŸ³å£°èªè­˜ä¸­...")
        user_text = self.stt.transcribe(speech_audio)

        if not user_text:
            print("  (éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ)")
            return None

        print(f"\nğŸ‘¤ ã‚ãªãŸ: {user_text}")

        # --- LLM ---
        print("\nğŸ¤– è€ƒãˆä¸­...")
        self.session.add_user_message(user_text)
        messages = self.session.build_messages()

        try:
            response_text = ""
            for token in self.llm.generate_stream(
                messages,
                temperature=self.config.temperature,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
                num_ctx=self.config.num_ctx,
                repeat_penalty=self.config.repeat_penalty,
            ):
                response_text += token
                print(token, end="", flush=True)
            print()

            if not response_text:
                return None

            self.session.add_assistant_message(response_text)

        except Exception as e:
            print(f"\nâŒ LLM ã‚¨ãƒ©ãƒ¼: {e}")
            if self.session._messages and self.session._messages[-1]["role"] == "user":
                self.session._messages.pop()
            return None

        # --- TTS & å†ç”Ÿ ---
        self._state = self.STATE_SPEAKING
        print("\nğŸ”Š èª­ã¿ä¸Šã’ä¸­...")
        try:
            wav_data = self.tts.synthesize(response_text)
            self.player.play_wav(wav_data, blocking=True)
        except Exception as e:
            print(f"âš ï¸  TTS/å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

        self._state = self.STATE_IDLE
        return response_text

    def _listen_for_speech(self, max_duration: float = 30.0) -> Optional[np.ndarray]:
        """
        VADã‚’ä½¿ã£ã¦ç™ºè©±åŒºé–“ã‚’æ¤œå‡ºã—ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™

        Args:
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ (ç§’)

        Returns:
            æ¤œå‡ºã•ã‚ŒãŸç™ºè©±ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã€‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯ Noneã€‚
        """
        self.vad.reset()
        result_audio = None
        start_time = time.time()

        def audio_callback(indata, frames, time_info, status):
            nonlocal result_audio
            if status:
                pass  # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ç­‰ã¯ç„¡è¦–
            frame = indata[:, 0].copy()  # ãƒ¢ãƒãƒ©ãƒ«ã«
            speech = self.vad.process_frame(frame)
            if speech is not None:
                self._audio_queue.put(speech)

        stream = self.recorder.open_stream(
            callback=audio_callback,
            frame_size=self.vad.frame_size,
        )

        with stream:
            while True:
                try:
                    # ç™ºè©±æ¤œå‡ºå¾…ã¡
                    speech = self._audio_queue.get(timeout=1.0)
                    return speech
                except queue.Empty:
                    elapsed = time.time() - start_time
                    if elapsed > max_duration:
                        print("  (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ)")
                        return None
                    if self.vad.is_speaking:
                        # ç™ºè©±ä¸­ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
                        print(".", end="", flush=True)

    def run_interactive(self) -> None:
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–éŸ³å£°å¯¾è©±ãƒ«ãƒ¼ãƒ—"""
        self._running = True
        print("\n" + "=" * 50)
        print(" ğŸ™ï¸  éŸ³å£°å¯¾è©±ãƒ¢ãƒ¼ãƒ‰")
        print("  Ctrl+C ã§çµ‚äº†")
        print("=" * 50)

        try:
            while self._running:
                self.process_voice_turn()
        except KeyboardInterrupt:
            print("\n\nçµ‚äº†ã—ã¾ã™...")
            self._running = False
            if self.session.turn_count > 0:
                saved = self.session.save()
                print(f"ä¼šè©±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {saved}")
            self.llm.close()

    def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã®è§£æ”¾"""
        self._running = False
        self.llm.close()
