# subpc_living — 要件定義書

## 1. 概要

サブPC上で動作する、**常時稼働型のインタラクティブ・パーソナルAI**を構築するプロジェクト。
マイク・カメラを常時ONにして環境情報・個人データを継続収集し、ユーザー個人に完全にフィットしたAIの実現を目指す。

インタラクションのイメージは**Gemini Liveのようなリアルタイム音声会話**。
ただし、クラウドではなく完全ローカルで動作し、かつ**会話開始時点で既にユーザーの状況・予定・嗜好・最近の行動を把握している**点が決定的な違い。
「今日何するんだったっけ？」ではなく、「今日の‥の件、準備できてる？」から会話が始まるイメージ。

すべての処理・データをローカルで完結させ、プライバシーを完全に担保する。

## 2. 目的

- **パーソナルAIの構築**: 個人のデータ（会話履歴、行動、嗜好、表情、声のトーン等）を蓄積し、自分専用のAIを育てる
- **常時インタラクション**: マイク・カメラで環境を常時センシングし、自然な対話を実現する
- **完全ローカル**: クラウドに一切依存せず、すべてのデータと推論をサブPC内に閉じる
- **継続学習・適応**: 蓄積データをもとに、応答品質・パーソナライズ度を継続的に向上させる

## 3. 特徴

- **常時稼働**: マイク・カメラを常時ONにし、環境を継続的にセンシング
- **マルチモーダル入力**: 音声（STT）・映像（顔認識・感情推定・物体認識）・テキストの複合入力
- **パーソナルメモリ**: 長期記憶DBに個人データを蓄積し、文脈を跨いだ応答が可能
- **ローカル実行**: すべての処理がサブPC上で完結。データが外部に送信されない
- **音声対話**: STT + LLM + TTS のパイプラインでハンズフリー会話
- **低コスト運用**: クラウドAPI利用料が不要

## 4. ハードウェア要件（サブPCスペック）

> **※ 未定 — 以下に随時追記**

| 項目 | スペック |
|------|---------|
| CPU | Intel Core i7-8700（6コア/12スレッド、3.2GHz〜4.6GHz） |
| GPU | NVIDIA Tesla P40（VRAM 24GB）※ GTX 1060から換装予定 |
| RAM | 16GB |
| ストレージ | SSD 512GB + SSD 256GB（合計約768GB） |
| OS | Ubuntu 24.04 LTS |
| 電源ユニット | 500W ⚠️ P40(250W)+i7-8700(65W)+他で余裕が少ない。安定稼働には550W以上推奨 |
| PCケース | フルレングスGPU搭載可能 |
| マイク | TBD（常時集音用。USB接続のコンデンサーマイク等を推奨） |
| カメラ | TBD（常時撮影用。USB Webカメラ。広角推奨） |
| スピーカー | TBD（TTS音声出力用） |
| その他 | 映像出力はCPU内蔵GPU（Intel UHD 630）で対応。P40のファン換装を検討 |

### VRAM配分見積もり（Tesla P40: 24GB）

| モジュール | 推定VRAM使用量 |
|-----------|----------------|
| LLM本体（13B Q4量子化） | 約8〜10GB |
| STT（Whisper medium） | 約1.5GB |
| TTS（Piper / VITS） | 約0.5GB |
| Vision（映像解析モデル） | 約1〜2GB |
| **合計** | **約11〜14GB / 24GB** |

> 24GB VRAMに対して十分な余裕あり。モデル拡大やRAG用の埋め込みモデル追加も可能。

## 5. 機能要件

### 5.1 常時センシング（入力系）

| # | 機能 | 説明 |
|---|------|------|
| F-01 | 常時音声入力 | マイクを常時ONにし、音声をリアルタイムでキャプチャ |
| F-02 | 音声認識（STT） | 音声をテキストに変換（Whisper等）。日本語対応必須 |
| F-03 | ウェイクワード検知 | 特定の呼びかけ（例:「ねぇ」「Hey」）でアクティブモードに切替 |
| F-04 | 常時カメラ入力 | Webカメラを常時ONにし、映像フレームを継続取得 |
| F-05 | 顔認識・感情推定 | ユーザーの表情・感情を読み取り、応答に反映 |
| F-06 | 物体・環境認識 | カメラ映像から周囲の物体・状況を認識 |

### 5.2 対話・応答（処理系） — Gemini Live型リアルタイム対話

| # | 機能 | 説明 |
|---|------|------|
| F-07 | テキスト対話 | テキスト入力に対してLLMが応答生成 |
| F-08 | 音声対話（ストリーミング） | Gemini Live的なリアルタイム音声対話。STT→LLM→TTSをストリーミングで接続し、低レイテンシな自然会話を実現 |
| F-09 | コンテキスト保持 | 直近のセッション内で会話文脈を維持 |
| F-10 | マルチモーダル推論 | 音声・映像・テキストの情報を統合してLLMが推論 |
| F-25 | **セッションプリロード** | 会話開始時に、ユーザープロファイル・今日の予定・最近の会話要約・PC活動ログを自動でシステムプロンプトに注入。「今何したい？」と聞く必要がない状態で会話が始まる |
| F-26 | **プロアクティブ発話** | AI側から能動的に話しかける。例: 予定時刻のリマインド、作業が長時間続いたら休憩提案、天気に応じた声かけ |
| F-27 | **割り込み・ターンテイク** | ユーザーが発話中にAIの応答を中断できる。Gemini Live的な自然なターンテイクを実現 |
| F-28 | **ストリーミングTTS** | LLMのトークン生成に合わせて逐次音声合成。全文完成を待たずに話し始める |

#### セッションプリロードの仕組み

会話開始時（ウェイクワード検知 or プロアクティブ発話時）に、以下を自動でシステムプロンプトに組み込む:

```
[System Prompt 自動構築]
├─ ユーザープロファイル（嗜好・性格・口調の好み等）
├─ 今日のスケジュール・予定（カレンダー連携 or 手動登録）
├─ 直近の会話要約（前回セッションの要点）
├─ 未完了タスク・次にやることリスト
├─ 最近のPC活動要約（どんな作業をしていたか）
├─ 現在の時刻・曜日・天気（ローカルデータ）
└─ カメラからの現在の環境情報（表情・服装・部屋の状態等）
```

> **結果**: AIは「今日14時から会議だったよね、資料の準備はできた？」のように、**文脈を理解した状態で会話を開始**できる。

### 5.3 パーソナルメモリ（記憶・学習系）

| # | 機能 | 説明 |
|---|------|------|
| F-11 | 会話履歴の永続保存 | すべての対話ログをDB/ファイルに保存 |
| F-12 | 長期記憶（ベクトルDB） | 過去の会話・個人情報をベクトル化して蓄積。RAGで検索・参照 |
| F-13 | ユーザープロファイル | 嗜好、習慣、スケジュール、関心事等の構造化データを蓄積 |
| F-14 | 自動要約・知識抽出 | 会話から重要情報を自動抽出し、プロファイルや長期記憶に反映 |
| F-15 | パーソナライズ応答 | 蓄積された個人データに基づき、応答スタイル・内容を最適化 |

### 5.4 PC挙動ログ収集

| # | 機能 | 説明 |
|---|------|------|
| F-19 | サブPC挙動ログ | サブPC自身のシステムログ（CPU/GPU/RAM使用率、温度、プロセス、ネットワーク等）を常時記録 |
| F-20 | メインPC挙動ログ | メインPCのアクティビティ（アクティブウィンドウ、キーストローク統計、アプリ使用時間、ブラウザ履歴等）を収集・送信 |
| F-21 | メインPC→サブPC転送 | メインPC上のログ収集エージェントがLAN経由でサブPCにデータを送信 |
| F-22 | ログの永続保存 | 収集したすべてのログをサブPCのDBに時系列で蓄積 |
| F-23 | アクティビティ分析 | ログデータをLLMに入力し、行動パターン・習慣・作業傾向を分析してプロファイルに反映 |
| F-24 | ダッシュボード表示 | 収集したログデータの可視化（日別アプリ使用時間、PC稼働率等） |

### 5.5 出力系

| # | 機能 | 説明 |
|---|------|------|
| F-16 | 音声合成（TTS） | LLMの応答テキストを音声に変換して出力 |
| F-17 | テキスト出力 | Web UI 等でテキストベースの応答も表示 |
| F-18 | 状態表示 | 現在のAIの状態（リスニング中/処理中/応答中等）を表示 |

## 6. 非機能要件

| カテゴリ | 要件 |
|---------|------|
| パフォーマンス | 音声応答のレイテンシ: ユーザー発話終了から2秒以内に音声応答開始を目標（ストリーミングTTSにより全文完成を待たない） |
| セッション起動 | プリロード完了まで1秒以内を目標。ユーザーを待たせない |
| 可用性 | 24時間365日常時稼働を想定。自動再起動・プロセス監視を導入 |
| セキュリティ | すべてのデータはローカル保存。外部通信は原則禁止。個人データは暗号化保存を検討 |
| 省電力 | 常時稼働のため、アイドル時のGPU消費電力制御（nvidia-smi -pl 等） |
| 拡張性 | モデルの差し替え・モジュール追加が容易なプラグイン設計 |
| データ保全 | 個人データの定期バックアップ。ストレージ冗長化を検討 |

## 7. システム構成

### 7.1 パイプライン概要

```
[マイク] → [VAD/ウェイクワード] → [Whisper STT] ──┐
                                                    ├→ [LLM + RAG] → [TTS] → [スピーカー]
[カメラ] → [Vision Model (顔/感情/物体)] ──────────┘        ↑↓
                                              [ベクトルDB / 長期記憶]
                                              [ユーザープロファイルDB]
[サブPC] → [システムモニタ] ────────┐
                                    ├→ [ログDB (時系列)] → [分析 → プロファイルDB]
[メインPC] → [ログ収集エージェント] ─┘```

### 7.2 使用技術・ツール（候補）

| カテゴリ | 候補 | 備考 |
|---------|------|------|
| LLM推論エンジン | llama.cpp (CUDA) / Ollama | GTX 1060でもCUDA対応。量子化モデルをGPU推論 |
| LLMモデル | **現行: 7B Q4_K_M**（gemma-2-7b, Qwen2.5-7B等） → P40後: 13〜14B | 6GB VRAMで7Bが上限。日本語対応モデル優先 |
| STT（音声認識） | faster-whisper (small/base) → P40後: medium/large | **現行はCPU実行**。i7-8700て12スレッドで実用可 |
| TTS（音声合成） | Piper (CPU) / Style-BERT-VITS2 | **CPU実行**。Piperは非常に軽量で日本語対応 |
| VAD（音声区間検出） | Silero VAD | CPU実行。軽量で高精度 |
| ウェイクワード | OpenWakeWord / Porcupine | 呼びかけ検知でアクティブモード切替 |
| Vision（映像解析） | YOLO (物体検出) / DeepFace (顔/感情) | **現行はCPU実行**。軽量モデルを選定 |
| ベクトルDB | ChromaDB / Qdrant | 長期記憶のベクトル検索用。RAGパイプラインの中核 |
| 埋め込みモデル | intfloat/multilingual-e5 等 | 日本語対応の埋め込みモデルでRAG検索精度を確保 |
| ユーザーデータDB | SQLite / PostgreSQL | プロファイル・構造化データの保存 |
| PC挙動ログ収集（サブPC） | psutil / Prometheus node_exporter | CPU/GPU/RAM/温度/プロセス等をリアルタイム収集 |
| PC挙動ログ収集（メインPC） | ActivityWatch / カスタムエージェント | アプリ使用時間・アクティブウィンドウ・ブラウザ履歴等 |
| ログ転送 | MQTT / REST API / rsync | メインPC → サブPCへのLAN内データ転送 |
| 時系列DB | InfluxDB / TimescaleDB | ログデータの時系列保存・クエリ |
| ダッシュボード | Grafana | ログデータの可視化 |
| オーケストレーション | Python (FastAPI / asyncio) | 各モジュールを非同期パイプラインで統合 |
| プロセス管理 | systemd / supervisord | 常時稼働・自動再起動 |
| フロントエンド | Web UI (Gradio / Open WebUI) | 状態表示・テキスト対話用。オプション |

### 7.3 GTX 1060での運用戦略（現行）

- **GPUはLLM専用**: 6GB VRAMをLLM推論に全振り（7B Q4_K_M）
- **STT/TTS/VisionはCPU実行**: i7-8700の12スレッドを活用
- **同時実行の制限**: LLM推論中はSTTを一時停止する等、排他制御が必要
- **レイテンシ**: P40比で遅くなるが、音声応答開始3〜5秒を目標
- **先にパイプラインを完成させる**: GPU換装後はモデル差し替えだけでスケールアップ可能な設計

### 7.4 P40換装後の注意点（将来）

- **FP16非対応**: Pascal世代のためFP16がFP32と同速度。INT8またはQ4/Q5量子化が有効
- **CUDAドライバ**: Ubuntu 24.04 + CUDA 12.x 対応確認が必要
- **映像出力なし**: Intel UHD 630で画面出力。BIOSで内蔵GPU優先に設定

## 8. 制約・前提条件

- サブPC上で動作すること（リモートサーバー不可）
- インターネット接続なしでも基本機能が利用可能であること
- **現行GPUはGTX 1060（6GB）**。LLMは7B Q4が上限、STT/TTS/VisionはCPU実行
- GTX 1060はPascal世代。FP16が実質非対応のため量子化（Q4/Q5）前提
- P40換装時に電源500Wでの安定性要検証（TDP 250W）
- カメラ・マイクの常時ONに伴う発熱・電力を考慮した設計が必要
- 個人データの取り扱いは自己責任。暗号化・アクセス制御を推奨
- メインPCにもログ収集エージェントのインストールが必要
- メインPC⇔サブPC間はLAN接続前提（同一ネットワーク内）
- **アーキテクチャはGPU換装を前提に設計**: モジュール分離し、モデル差し替えだけでP40に移行可能にする

## 9. 追加ハードウェア検討

| アイテム | 優先度 | 推定コスト | 備考 |
|---------|--------|-----------|------|
| USB コンデンサーマイク | 必須 | 2,000〜5,000円 | 常時集音に適したもの |
| USB Webカメラ（広角） | 必須 | 3,000〜8,000円 | 常時撮影。広角で部屋全体をカバー |
| スピーカー / ヘッドセット | 必須 | 手持ちがあれば不要 | TTS出力用 |
| RAM増設（16GB→32GB） | 推奨 | 3,000〜5,000円 | 複数モデル同時稼働時の安定性向上 |
| 電源ユニット換装（650W） | 推奨 | 3,000〜5,000円 | P40換装時に必要。GTX 1060運用中は不要 |
| P40用ファン換装 | 推奨 | 2,000〜4,000円 | P40換装時に検討。ブロワーファンの騒音対策 |
| **Tesla P40本体** | **将来** | **15,000〜25,000円** | **VRAM 24GBへのアップグレード。開発が進んでから購入** |

## 10. 開発フェーズ（案）

| フェーズ | 内容 | 目標 | 状態 |
|---------|------|------|------|
| Phase 1 | 環境構築 | Ubuntu + CUDA + **GTX 1060**セットアップ。Ollamaインストール | ✅ **完了** |
| Phase 2 | テキスト対話 | 7Bモデル(Q4)でテキストベース対話を実現 | ✅ **完了** |
| Phase 3 | 音声対話 | STT(faster-whisper/CPU) + TTS(kokoro-onnx/CPU) + VAD(Silero/Energy) + ストリーミングTTS | ✅ **完了** |
| Phase 4 | 長期記憶 | ChromaDB + multilingual-e5-small + RAG で会話履歴の蓄積・参照 | ✅ **完了** |
| Phase 5 | 映像入力 | カメラ + OpenCV顔検出 + emotion-ferplus感情推定（CPU実行） | ✅ **完了** |
| Phase 6 | PCログ収集 | psutil + SQLite でサブPCのシステムメトリクスを常時収集・蓄積・LLM注入 | ✅ **完了** |
| Phase 7 | パーソナライズ | セッションプリロード・プロアクティブ発話・応答最適化 | ✅ **完了** |
| Phase 8 | 常時稼働化 | systemd 管理、自動再起動、ヘルスチェック、GPU省電力制御 | ✅ **完了** |
| **Phase 9** | **GPU換装** | **P40に換装、モデル13B化、全モジュールGPU化、レイテンシ改善** | ✅ **完了** |

## 11. 今後の検討事項

- ファインチューニング（LoRA等）による個人特化モデル作成の可能性
- 複数部屋対応（マイク・カメラの拡張）
- スマートホーム連携（Home Assistant等）
- モバイル端末からのリモートアクセス（LAN内限定）
- 感情に応じた応答スタイルの動的変更
- 日記・ライフログの自動生成
- PCログからの作業効率分析・改善提案
- メインPCの操作コンテキストをリアルタイムでLLMに渡し、作業アシスタントとして活用
- Google Calendar / Notion 等のローカルエクスポートデータをスケジュール源として取り込み
- AI側の「性格」・「口調」のカスタマイズ設定
- 音声クローン（自分の声でTTSする）の可能性調査

---

## ライセンス

MIT
